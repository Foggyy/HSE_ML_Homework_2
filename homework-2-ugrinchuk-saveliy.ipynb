{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Made by**: Saveliy Ugrinchuk","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:28.526260Z","iopub.execute_input":"2022-04-01T20:45:28.526760Z","iopub.status.idle":"2022-04-01T20:45:28.532356Z","shell.execute_reply.started":"2022-04-01T20:45:28.526560Z","shell.execute_reply":"2022-04-01T20:45:28.531520Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"markdown","source":"## **Loading dataframes**","metadata":{}},{"cell_type":"code","source":"train_dataframe = pd.read_csv('../input/hse-aml-2022/books_train.csv')\ntest_dataframe = pd.read_csv('../input/hse-aml-2022/books_test.csv')\nexample = pd.read_csv('../input/hse-aml-2022/books_test.csv')\nlen(example)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:28.799229Z","iopub.execute_input":"2022-04-01T20:45:28.799758Z","iopub.status.idle":"2022-04-01T20:45:28.886239Z","shell.execute_reply.started":"2022-04-01T20:45:28.799709Z","shell.execute_reply":"2022-04-01T20:45:28.885072Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"markdown","source":"## **Exploring and clearing dataset**","metadata":{}},{"cell_type":"code","source":"train_dataframe","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:29.048022Z","iopub.execute_input":"2022-04-01T20:45:29.048414Z","iopub.status.idle":"2022-04-01T20:45:29.080480Z","shell.execute_reply.started":"2022-04-01T20:45:29.048383Z","shell.execute_reply":"2022-04-01T20:45:29.079079Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"train_dataframe.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:29.264072Z","iopub.execute_input":"2022-04-01T20:45:29.264372Z","iopub.status.idle":"2022-04-01T20:45:29.288639Z","shell.execute_reply.started":"2022-04-01T20:45:29.264345Z","shell.execute_reply":"2022-04-01T20:45:29.287663Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"markdown","source":"Renaming column **'num_pages'** since it has unnecessary spaces in the name","metadata":{}},{"cell_type":"code","source":"train_dataframe.rename(columns = {'  num_pages': 'num_pages'}, inplace=True)\ntest_dataframe.rename(columns = {'  num_pages': 'num_pages'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:29.471517Z","iopub.execute_input":"2022-04-01T20:45:29.472946Z","iopub.status.idle":"2022-04-01T20:45:29.481739Z","shell.execute_reply.started":"2022-04-01T20:45:29.472860Z","shell.execute_reply":"2022-04-01T20:45:29.480742Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"code","source":"train_dataframe.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:29.670438Z","iopub.execute_input":"2022-04-01T20:45:29.670701Z","iopub.status.idle":"2022-04-01T20:45:29.700271Z","shell.execute_reply.started":"2022-04-01T20:45:29.670674Z","shell.execute_reply":"2022-04-01T20:45:29.699414Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"markdown","source":"Books with 0 or 4736 pages seem unrealistic, so we will eliminate books with fewer than 10 pages or more than 2000\n\n**isbn** and **isbn13** don't look like useful metrics, as they just represent a book number and we already have **bookID**, so they can be removed from the dataframe.","metadata":{}},{"cell_type":"code","source":"# train dataframe\ntrain_dataframe = train_dataframe[train_dataframe.num_pages > 10]\ntrain_dataframe = train_dataframe[train_dataframe.num_pages <= 2000]\ntrain_dataframe = train_dataframe.drop(columns=['isbn', 'isbn13'])\n# test dataframe\ntest_dataframe = test_dataframe.drop(columns=['isbn', 'isbn13'])\n\ntrain_dataframe.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:29.880258Z","iopub.execute_input":"2022-04-01T20:45:29.880550Z","iopub.status.idle":"2022-04-01T20:45:29.914764Z","shell.execute_reply.started":"2022-04-01T20:45:29.880519Z","shell.execute_reply":"2022-04-01T20:45:29.913555Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"markdown","source":"Changing **language_code** from string values to int values, turning them into categories. Same procedure for **publisher** column.","metadata":{}},{"cell_type":"code","source":"language_codes = {'language_code': {'en-US': 'eng','en-CA': 'eng','en-GB': 'eng'}}\n# train dataframe\ntrain_dataframe.replace(language_codes, inplace=True)\ntrain_dataframe.language_code = train_dataframe.language_code.astype('category').cat.codes\ntrain_dataframe.publisher = train_dataframe.publisher.astype('category').cat.codes\n# test dataframe\ntest_dataframe.replace(language_codes, inplace=True)\ntest_dataframe.language_code = test_dataframe.language_code.astype('category').cat.codes\ntest_dataframe.publisher = test_dataframe.publisher.astype('category').cat.codes\n\n# Converting publication_date to year\n# test dataframe\ntrain_dataframe.publication_date = pd.to_datetime(train_dataframe.publication_date, errors='coerce', format='%m/%d/%Y')\ntrain_dataframe.publication_date = pd.DatetimeIndex(train_dataframe.publication_date).year\ntrain_dataframe = train_dataframe.dropna()   # drop empty values\ntrain_dataframe['year'] = train_dataframe.publication_date.astype(int)\n# train dataframe\ntest_dataframe.publication_date = pd.to_datetime(test_dataframe.publication_date, errors='coerce', format='%m/%d/%Y')\ntest_dataframe.publication_date = pd.DatetimeIndex(test_dataframe.publication_date).year\ntest_dataframe = test_dataframe.dropna()   # drop empty values\ntest_dataframe['year'] = test_dataframe.publication_date.astype(int)\n\n\n# Dropping title and authors since I can't imagine how they can be used for the model. Also drop 'publication_date' because it is no longer needed\n# train dataframe\ntrain_dataframe = train_dataframe.drop(columns=['title', 'authors', 'publication_date'])\n# test dataframe\ntest_dataframe = test_dataframe.drop(columns=['title', 'authors', 'publication_date'])","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:30.063390Z","iopub.execute_input":"2022-04-01T20:45:30.064791Z","iopub.status.idle":"2022-04-01T20:45:30.151743Z","shell.execute_reply.started":"2022-04-01T20:45:30.064712Z","shell.execute_reply":"2022-04-01T20:45:30.150798Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"train_dataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:30.201009Z","iopub.execute_input":"2022-04-01T20:45:30.202003Z","iopub.status.idle":"2022-04-01T20:45:30.217865Z","shell.execute_reply.started":"2022-04-01T20:45:30.201928Z","shell.execute_reply":"2022-04-01T20:45:30.216782Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"markdown","source":"## **Training and testing of the model**","metadata":{}},{"cell_type":"markdown","source":"Separating the metric of the average rating from the rest of the dataframe for further splitting into samples of training and test data","metadata":{}},{"cell_type":"code","source":"average_ratings = train_dataframe.average_rating\ntrain_dataframe = train_dataframe.drop(columns=['average_rating'])\naverage_ratings","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:30.294119Z","iopub.execute_input":"2022-04-01T20:45:30.294855Z","iopub.status.idle":"2022-04-01T20:45:30.309170Z","shell.execute_reply.started":"2022-04-01T20:45:30.294740Z","shell.execute_reply":"2022-04-01T20:45:30.308093Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"markdown","source":"Test data split will contain 30% of the data","metadata":{}},{"cell_type":"code","source":"X_Train, X_Test, Y_Train, Y_Test = train_test_split(train_dataframe, average_ratings, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:30.379799Z","iopub.execute_input":"2022-04-01T20:45:30.380200Z","iopub.status.idle":"2022-04-01T20:45:30.391934Z","shell.execute_reply.started":"2022-04-01T20:45:30.380165Z","shell.execute_reply":"2022-04-01T20:45:30.390480Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"markdown","source":"Trying to define best model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\n\nmodel_linear = LinearRegression()\nmodel_ridge = Ridge()\nmodel_GBR = GradientBoostingRegressor()\n\nmodel_linear.fit(X_Train, Y_Train)\nprint('LinearRegression', model_linear.score(X_Test, Y_Test) * 100)\n\nmodel_ridge.fit(X_Train, Y_Train)\nprint('Ridge', model_ridge.score(X_Test, Y_Test) * 100)\n\nmodel_GBR.fit(X_Train, Y_Train)\nprint('GradientBoostingRegressor', model_GBR.score(X_Test, Y_Test) * 100)\n\nregr = AdaBoostRegressor()\nregr.fit(X_Train, Y_Train)\nprint('AdaBoostRegressor', regr.score(X_Test, Y_Test) * 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:30.459111Z","iopub.execute_input":"2022-04-01T20:45:30.459490Z","iopub.status.idle":"2022-04-01T20:45:31.600642Z","shell.execute_reply.started":"2022-04-01T20:45:30.459451Z","shell.execute_reply":"2022-04-01T20:45:31.599238Z"},"trusted":true},"execution_count":222,"outputs":[]},{"cell_type":"markdown","source":"GradientBoostingRegressor has better score, I will use it to predict the ratings of books","metadata":{}},{"cell_type":"code","source":"test_dataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:31.603334Z","iopub.execute_input":"2022-04-01T20:45:31.604125Z","iopub.status.idle":"2022-04-01T20:45:31.616124Z","shell.execute_reply.started":"2022-04-01T20:45:31.604067Z","shell.execute_reply":"2022-04-01T20:45:31.614811Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"code","source":"predicted_data = model_GBR.predict(test_dataframe)\npredicted_data","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:31.618163Z","iopub.execute_input":"2022-04-01T20:45:31.618828Z","iopub.status.idle":"2022-04-01T20:45:31.638650Z","shell.execute_reply.started":"2022-04-01T20:45:31.618742Z","shell.execute_reply":"2022-04-01T20:45:31.637569Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"code","source":"books_sample_submission = pd.read_csv('../input/hse-aml-2022/books_sample_submission.csv')\nbooks_sample_submission['average_rating'] = predicted_data\nbooks_sample_submission.to_csv('predicted_ratings_GBR_submission.csv', index=False)\nprint(books_sample_submission)","metadata":{"execution":{"iopub.status.busy":"2022-04-01T20:45:31.640168Z","iopub.execute_input":"2022-04-01T20:45:31.640718Z","iopub.status.idle":"2022-04-01T20:45:31.670639Z","shell.execute_reply.started":"2022-04-01T20:45:31.640685Z","shell.execute_reply":"2022-04-01T20:45:31.669815Z"},"trusted":true},"execution_count":225,"outputs":[]}]}